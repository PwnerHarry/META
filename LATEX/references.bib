@article{white2016greedy,
author = {Martha White and Adam White},
title = {A Greedy Approach to Adapting the Trace Parameter for Temporal Difference Learning},
journal = {arXiv},
volume = {abs/1607.00446},
year = {2016},
//url = {http://arxiv.org/abs/1607.00446}
}

@article{watkins1989learning,
  title={Learning from Delayed Rewards},
  author={Watkins, Christopher John Cornish Hellaby},
  year={1989},
  journal = {PhD Thesis, Cambridge University},
  publisher={King's College, Cambridge}
}

@article{sherstan2018directly,
  author    = {Craig Sherstan and
               Brendan Bennett and
               Kenny Young and
               Dylan Ashley and
               Adam White and
               Martha White and
               Richard Sutton},
  title     = {Directly Estimating the Variance of the {\(\lambda\)}-Return Using
               Temporal-Difference Methods},
  journal   = {arXiv},
  volume    = {abs/1801.08287},
  year      = {2018},
  //url       = {http://arxiv.org/abs/1801.08287}
}

@article{yang2018unified,
  author    = {Long Yang and
               Minhao Shi and
               Qian Zheng and
               Wenjia Meng and
               Gang Pan},
  title     = {A Unified Approach for Multi-step Temporal-Difference Learning with
               Eligibility Traces in Reinforcement Learning},
  journal   = {arXiv},
  volume    = {abs/1802.03171},
  year      = {2018},
  //url       = {http://arxiv.org/abs/1802.03171}
}

@article{sharma2017mix,
  author    = {Sahil Sharma and
               Girish Raguvir J and
               Srivatsan Ramesh and
               Balaraman Ravindran},
  title     = {Learning to Mix n-Step Returns: Generalizing lambda-Returns for Deep
               Reinforcement Learning},
  journal   = {arXiv},
  volume    = {abs/1705.07445},
  year      = {2017},
  //url       = {http://arxiv.org/abs/1705.07445}
}

@article{deasis2017multi,
  author    = {Kristopher De Asis and
               J. Fernando Hernandez{-}Garcia and
               G. Zacharias Holland and
               Richard Sutton},
  title     = {Multi-step Reinforcement Learning: {A} Unifying Algorithm},
  journal   = {arXiv},
  volume    = {abs/1703.01327},
  year      = {2017},
  //url       = {http://arxiv.org/abs/1703.01327}
}

@article{seijen2015true,
  author    = {Harm van Seijen and
               Ashique Rupam Mahmood and
               Patrick Pilarski and
               Marlos Machado and
               Richard Sutton},
  title     = {True Online Temporal-Difference Learning},
  journal   = {ArXiv},
  volume    = {abs/1512.04087},
  year      = {2015},
  //url       = {http://arxiv.org/abs/1512.04087},
}

@article{maei2011gradient,
  author    = {Hamid Maei},
  title     = {Gradient Temporal-difference Learning Algorithms},
  journal   = {PhD Thesis},
  volume    = {University of Alberta},
  year      = {2011},
  //url       = {http://incompleteideas.net/Talks/gradient-TD-2011.pdf}
}

@inproceedings{sutton2009fast,
  title={Fast gradient-descent methods for temporal-difference learning with linear function approximation},
  author={Sutton, Richard and Maei, Hamid and Precup, Doina and Bhatnagar, Shalabh and Silver, David and Szepesv{\'a}ri, Csaba and Wiewiora, Eric},
  booktitle={ICML},
  pages={993-1000},
  year={2009},
  //url={https://dl.acm.org/citation.cfm?id=1553501}
}

@inproceedings{sutton2009convergent,
title = {A Convergent {$\scriptO(n)$} Temporal-difference Algorithm for Off-policy Learning with Linear Function Approximation},
author = {Sutton, Richard and Hamid Maei and Csaba Szepesv\'{a}ri},
booktitle = {Neural Information Processing Systems},
//editor = {D. Koller and D. Schuurmans and Y. Bengio and L. Bottou},
pages = {1609-1616},
year = {2009},
//url = {http://papers.nips.cc/paper/3626-a-convergent-on-temporal-difference-algorithm-for-off-policy-learning-with-linear-function-approximation}
}

@InProceedings{sutton2014interim,
  title =   {A new {Q($\lambda$)} with Interim Forward View and Monte Carlo Equivalence},
  author = {Richard Sutton and Ashique Rupam Mahmood and Doina Precup and Hado Hasselt},
  booktitle = 	 {ICML},
  pages = 	 {568-576},
  year = 	 {2014},
  volume = 	 {32},
  number =       {2},
  //series = 	 {Proceedings of Machine Learning Research},
  //url = 	 {http://proceedings.mlr.press/v32/sutton14.html},
}

@inproceedings{sutton2011horde,
 author = {Sutton, Richard and Modayil, Joseph and Delp, Michael and Degris, Thomas and Pilarski, Patrick M. and White, Adam and Precup, Doina},
 title = {{Horde}: A Scalable Real-time Architecture for Learning Knowledge from Unsupervised Sensorimotor Interaction},
 booktitle = {International Conference on Autonomous Agents and Multiagent Systems},
 //series = {AAMAS '11},
 year = {2011},
 //isbn = {0-9826571-6-1, 978-0-9826571-6-4},
 //location = {Taipei, Taiwan},
 pages = {761-768},
 //numpages = {8},
 //url = {http://dl.acm.org/citation.cfm?id=2031678.2031726},
 //acmid = {2031726},
 //publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
 //address = {Richland, SC},
 //keywords = {artificial intelligence, knowledge representation, off-policy learning, real-time, reinforcement learning, robotics, temporal-difference learning, value function approximation},
}
@inproceedings{hasselt2014true,
  title={Off-policy {TD($\lambda$)} with a true online equivalence},
  author={van Hasselt, Hado and Mahmood, A Rupam and Sutton, Richard},
  booktitle={Conference on Uncertainty in Artificial Intelligence},
  pages={330-339},
  year={2014},
  //url = {http://auai.org/uai2014/proceedings/individuals/324.pdf}
}
@book{DBLP:books/lib/SuttonB98,
  author    = {Richard Sutton and Andrew Barto},
  title     = {Reinforcement learning - an introduction},
  series    = {Adaptive computation and machine learning},
  publisher = {{MIT} Press},
  year      = {1998},
  //url       = {http://www.worldcat.org/oclc/37293240},
  //isbn      = {0262193981},
  //timestamp = {Wed, 26 Apr 2017 01:00:00 +0200},
}
@Article{Singh1996,
author="Singh, Satinder and Sutton, Richard",
title="Reinforcement learning with replacing eligibility traces",
journal="Machine Learning",
year="1996",
month="Mar",
day="01",
volume="22",
number="1",
pages="123--158",
//issn="1573-0565",
//doi="10.1007/BF00114726",
//url="https://doi.org/10.1007/BF00114726"
}
@inproceedings{dabney2012adaptive,
  title={Adaptive step-size for online temporal difference learning},
  author={Dabney, William and Barto, Andrew G},
  booktitle={AAAI},
  year={2012}
}
@inproceedings{kearns2000bias,
  title={Bias-Variance Error Bounds for Temporal Difference Updates.},
  author={Kearns, Michael J and Singh, Satinder P},
  booktitle={COLT},
  pages={142-147},
  year={2000}
}
@article{schapire1996worst,
  title={On the worst-case analysis of temporal-difference learning algorithms},
  author={Schapire, Robert E and Warmuth, Manfred K},
  journal={Machine Learning},
  volume={22},
  number={1-3},
  pages={95-121},
  year={1996},
  publisher={Springer}
}
@inproceedings{singh1997analytical,
  title={Analytical mean squared error curves in temporal difference learning},
  author={Singh, Satinder P and Dayan, Peter},
  booktitle={NIPS},
  pages={1054-1060},
  year={1997}
}
@inproceedings{konidaris2011td_gamma,
  title={TD\_gamma: Re-evaluating Complex Backups in Temporal Difference Learning},
  author={Konidaris, George and Niekum, Scott and Thomas, Philip S},
  booktitle={NIPS},
  pages={2402-2410},
  year={2011}
}